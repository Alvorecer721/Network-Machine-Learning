import sys
sys.path.append("../")  # To import utils

from utils import *
import numpy as np
import networkx as nx
from tqdm import tqdm
import pickle

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
import xgboost


def simple_handcrafted_features(graph):
    features = {}
    features["degree"] = nx.degree(graph)
    features["clustering_coeff"] = nx.clustering(graph)
    # Generalization of eigenvector centrality
    features["katz_centrality"] = nx.katz_centrality(graph)
    # About n. shortest paths between node
    features["betweenness_centrality"] = nx.betweenness_centrality(graph)
    # About all closed walks around each nodes
    features["harmonic_centrality"] = nx.harmonic_centrality(graph)
    features["closeness_centrality"] = nx.closeness_centrality(graph)
    features["pagerank"] = nx.pagerank(graph)
    features["avg_neighbours_degree"] = nx.average_neighbor_degree(graph)
    # features["eccentricity"] = nx.eccentricity(graph)
    return features


def features_dict_to_vec(graph, features):
    feature_header =  list(features.keys())

    features_out = {}
    for node in graph.nodes():
        row = []
        for feature in feature_header:
            row.append(features[feature][node])
        features_out[node] = np.array(row)
    return features_out, feature_header

all_cities = list_cities()
graphs = [load_graph(c, "bus") for c in all_cities]


for city, graph in tqdm(zip(all_cities, graphs), desc="Computing simple features...", total=len(all_cities)):
    features = simple_handcrafted_features(graph)
    features, header = features_dict_to_vec(graph, features)
    pkl = {
        "features": features,
        "header": header,
    }
    save_fname = os.path.join("simple_features", city + ".pkl")

    with open(save_fname, "wb") as f:
        pickle.dump(pkl, f)