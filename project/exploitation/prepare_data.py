import sys

sys.path.append("../")  # To import utils

from utils import load_graph as _load_graph, list_cities, symmetrize_adj
import numpy as np
import networkx as nx
from tqdm import tqdm
import pickle
import os
from node2vec import Node2Vec
import torch
import torch_geometric as pyg


def create_data_dirs():
    """Make sure data folder exists for every city"""
    for city in list_cities():
        dirname = os.path.join("data", city)
        if not os.path.exists(dirname):
            os.makedirs(dirname)


def load_graph(city):
    """Load city's bus network with non-zero degree nodes

    Args:
        city (str): City's name

    Returns:
        nx.Graph: Bus network graph
    """
    # Load bus graph, nodes with positive degree only
    graph = _load_graph(city, "bus")
    kept_nodes = [n for n, deg in graph.degree() if deg > 0]
    graph = graph.subgraph(kept_nodes)
    return graph


def compute_simple_handcrafted_features(graph):
    """Compute handcrafted features for a graph

    Args:
        graph (nx.Graph): input graph

    Returns:
        dict: Dictionary of features. Each subdict is accessible by node id (to query a particular feature)
    """
    features = {}
    features["degree"] = nx.degree(graph)
    features["clustering_coeff"] = nx.clustering(graph)
    # Generalization of eigenvector centrality
    features["katz_centrality"] = nx.katz_centrality(graph)
    # About n. shortest paths between node
    features["betweenness_centrality"] = nx.betweenness_centrality(graph)
    # About all closed walks around each nodes
    features["harmonic_centrality"] = nx.harmonic_centrality(graph)
    features["closeness_centrality"] = nx.closeness_centrality(graph)
    features["pagerank"] = nx.pagerank(graph)
    features["avg_neighbours_degree"] = nx.average_neighbor_degree(graph)
    return features


def node_idx_mapping(city):
    """Compute a mapping from old node idx to contiguous count (nodes from original graph are not and do not start at 0)

    Args:
        city (str): City's name

    Returns:
        dict: int -> int dict, mapping node indices from old to new
    """
    fname = os.path.join("data", city, "idx_map.ckp")

    if os.path.exists(fname):
        with open(fname, "rb") as f:
            node_old_to_new_idxs = pickle.load(f)
    else:
        graph = load_graph(city)
        node_old_to_new_idxs = {}
        for node in graph.nodes():
            node_old_to_new_idxs[node] = len(node_old_to_new_idxs)

        fname = os.path.join("data", city, "idx_map.ckp")
        with open(fname, "wb") as f:
            pickle.dump(node_old_to_new_idxs, f)

    return node_old_to_new_idxs


def prepare_simple_handcrafted_features(city):
    """Compute handcrafted features and save then into data/city/

    Args:
        city (str): City's name
    """
    graph = load_graph(city)
    features = compute_simple_handcrafted_features(graph)

    o2n = node_idx_mapping(city)
    n2o = {v: k for k, v in o2n.items()}

    feature_header = list(features.keys())
    features_out = []

    for new_idx in range(graph.number_of_nodes()):
        old_idx = n2o[new_idx]
        node_features = [features[feat][old_idx] for feat in feature_header]
        features_out.insert(new_idx, node_features)

    features_out = np.array(features_out)

    np.save(os.path.join("data", city, "handcrafted.npy"), features_out)
    with open(os.path.join("data", city, "handcrafted-header.txt"), "w") as f:
        f.write(",".join(feature_header))


def prepare_spectral_features(city, k=100):
    """Extract features from the eigenvectors of each citie's bus network.
    Note: the graph was symmetrized before computing the normalized graph Laplacian

    Args:
        city (str): city's name
        k1 (int, optional): Number of smallest eigenvectors to use. Defaults to 5.
        k2 (int, optional): Number of interleaved eigenvectors to use. Defaults to 5.

    Returns:
        np.ndarray: Array of spectral features
    """
    spectral_fname = os.path.join("data", "spectral", city + ".pkl")
    with open(spectral_fname, "rb") as f:
        ckp = pickle.load(f)

    lam = ckp["lam"]
    U = ckp["U"]
    symm_adj_loaded = ckp["symm_adj"]
    graph = load_graph(city)
    curr_adj = symmetrize_adj(graph)
    # Sanity check
    assert np.all(curr_adj == symm_adj_loaded)

    argsort = np.argsort(lam)
    lam = lam[argsort]
    U = U[:, argsort]

    # Take first k eigenvectors
    top_k = U[:, :k]
    spectral_features = top_k
    """
    # Take k, interleaved
    n = U.shape[0]
    idxs = np.linspace(0, n - 1, k2).astype(int)
    interleave_k = U[:, idxs]

    spectral_features = np.concatenate([top_k, interleave_k], axis=1)
    """
    save_fname = os.path.join("data", city, f"spectral_{k}.npy")
    np.save(save_fname, spectral_features)
    return spectral_features


def prepare_avg_duration_target(city):
    """Prepare avg_duration target for edge regression task

    Args:
        city (str): Citie's name

    Returns:
        (np.ndarray, np.ndarray): Array of edge indices (shape (2, n_edge)), Array of targets (shape (n_edge,))
    """
    graph = load_graph(city)
    o2n_idx = node_idx_mapping(city)

    new_edges = []
    targets = []
    edges = graph.edges()
    for e in edges:
        (u, v) = e
        new_edges.append((o2n_idx[u], o2n_idx[v]))
        targets.append(edges[e]["duration_avg"])

    new_edges = np.array(new_edges)
    targets = np.array(targets)

    np.save(os.path.join("data", city, "edges.npy"), new_edges)
    np.save(os.path.join("data", city, "avg_duration.npy"), targets)

    return new_edges, targets


def n2v_feature_extraction(
    graph,
    num_features=1,
    p=1.0,
    q=1.0,
    walk_length=80,
    per_vertex_num_walks=10,
    skip_gram_window=5,
    seed=0,
):
    """Extract Node2Vec features from graph

    Args:
        graph (nx.Graph): Networkx graph
        num_features (int, optional): Number of Node2Vec features per node. Defaults to 1.
        p (float, optional): Node2Vec p's parameter. Defaults to 1.0.
        q (float, optional): Node2Vec q's parameter. Defaults to 1.0.
        walk_length (int, optional): Node2Vec's random walk length. Defaults to 80.
        per_vertex_num_walks (int, optional): Number of walks per node to train skip-gram. Defaults to 10.
        skip_gram_window (int, optional): Skip-gram window. Defaults to 5.
        seed (int, optional): Random seed. Defaults to 0.

    Returns:
        np.ndarray: Array of Node2Vec features
    """
    np.random.seed(seed)
    n2v = Node2Vec(
        graph,
        p=p,
        q=q,
        seed=seed,
        dimensions=num_features,
        quiet=True,
        walk_length=walk_length,
        num_walks=per_vertex_num_walks,
    )
    model = n2v.fit(window=skip_gram_window)
    features = model.wv[np.arange(graph.number_of_nodes())]
    return features


def prepare_n2v_features(city):
    """Compute and store Node2Vec features for training

    Args:
        city (str): City's name

    Returns:
        np.ndarray: Array of Node2Vec features for different parameters
    """
    graph = load_graph(city)
    # Uniform random walk
    feats_1 = n2v_feature_extraction(
        graph,
        num_features=50,
        p=1.0,
        q=1.0,
    )
    # DFS-like RWs
    feats_2 = n2v_feature_extraction(
        graph,
        num_features=50,
        p=2.0,
        q=1.0,
    )
    # BFS-like RWs
    feats_3 = n2v_feature_extraction(
        graph,
        num_features=50,
        p=1.0,
        q=2.0,
    )

    features = np.concatenate([feats_1, feats_2, feats_3], axis=1)
    np.save(os.path.join("data", city, "n2v_features.npy"), features)
    return features


def neg_sample_edges(
    num_nodes,
    real_edges,
    num_fake_edges,
    seed,
):
    """Create inexistent edges from the graph (useful for edge prediction)

    Args:
        num_nodes (int): Number of nodes in original graph
        real_edges (list): List of real edges of the graph
        num_fake_edges (int): Number of non-existing edges to sample
        seed (int): Random seed

    Returns:
        np.ndarray: Edge list of shape (2, n_edges) (pytorch geometric convention)
    """
    np.random.seed(seed)
    new_edges = []
    original_edges = set(tuple(e) for e in real_edges.transpose())
    existing_edges = original_edges.copy()
    while len(new_edges) < num_fake_edges:
        (u, v) = np.random.randint(0, num_nodes, size=(2,))
        if u == v:
            continue

        e = (u, v)
        if e not in existing_edges:
            existing_edges.add(e)
            new_edges.append(e)

    assert (
        len(set(new_edges).union(original_edges))
        == real_edges.shape[1] + num_fake_edges
    )
    new_edges = np.array(new_edges).transpose()
    return new_edges


def load_features(
    city,
    features=None,
    task="duration_regr",
    neg_sample_ratio=1.0,
    format="torch",
    seed=0,
):
    """Load some features for a city

    Args:
        city (str): City's name
        features (list, optional): List of features to load. If None, load handcrafted, node2vec and 5 x 2 spectral features. Defaults to None.
        task (str, optional): Task of interest. Possible values: "duration_regr" and "link_pred". Defaults to "duration_regr".
        neg_sample_ratio (float, optional): Ratio of inexistent edges to sample. A ratio of k means we sample k * num_edges non_existing edges. Defaults to 1.0.
        format (str, optional): "numpy" or "torch". Defaults to "torch".
        seed (int, optional): Random seed. Defaults to 0.

    Raises:
        ValueError: _description_
        ValueError: _description_

    Returns:
        Data: Pytorch geometric Data object with fields x, y and edge_index set.
    """
    if features is None:
        features = ["handcrafted", "n2v_features", "spectral_100"]
    # Load all features and concatenate into array of shape (n_example, n_features)
    features_array = []
    for f in features:
        feats = np.load(os.path.join("data", city, f + ".npy"))
        features_array.append(feats)

    # Load edges into array of shape (2, n_edges), pyg convention
    features_array = np.concatenate(features_array, axis=1)
    edge_index = np.load(os.path.join("data", city, "edges.npy"))
    edge_index = edge_index.transpose()

    # Prepare edge labels into array of shape (n_edges)
    if task == "duration_regr":
        labels = np.load(os.path.join("data", city, "avg_duration.npy"))
        labels = labels

    elif task == "link_pred":
        _, n_edges = edge_index.shape
        labels = np.ones((n_edges,))
        # Sample non-existing edges (optional)
        no_edges = neg_sample_edges(
            num_nodes=features_array.shape[0],
            real_edges=edge_index,
            num_fake_edges=int(neg_sample_ratio * n_edges),
            seed=seed,
        )
        if no_edges.size > 0:
            # If use negative sampling
            no_edges_labels = np.zeros((no_edges.shape[1],))
            edge_index = np.concatenate([edge_index, no_edges], axis=1)
            labels = np.concatenate([labels, no_edges_labels], axis=0)

    else:
        raise ValueError(f"Unknown task {task}")

    features_array = features_array.astype(np.float32)
    labels = labels.astype(np.float32)

    # If data used with pyg, need fields to be torch tensors
    if format == "torch":
        features_array = torch.tensor(features_array)
        edge_index = torch.tensor(edge_index)
        labels = torch.tensor(labels)

    elif format == "numpy":
        pass
    else:
        raise ValueError(f"Unknown return format {format}")

    return pyg.data.Data(
        x=features_array,
        edge_index=edge_index,
        y=labels,
    )


if __name__ == "__main__":
    create_data_dirs()
    all_cities = list_cities()
    """
    for city in tqdm(all_cities, desc="Preparing handcrafted features"):
       prepare_simple_handcrafted_features(city)
    """

    for city in tqdm(all_cities, desc="Prepare spectral features"):
        prepare_spectral_features(city)

    #for city in tqdm(all_cities, desc="Prepare n2v features"):
    #    prepare_n2v_features(city)

    #for city in tqdm(all_cities, desc="Prepare avg duration targets"):
    #    prepare_avg_duration_target(city)

    print("Done")
